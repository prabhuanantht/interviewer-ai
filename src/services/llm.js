// Basic abstraction for LLM calls. 
// Currently tailored for Gemini (Google Generative AI) as it's often free/easier to access, 
// but structured to allow swapping.

const SYSTEM_PROMPT_TEMPLATE = (role, difficulty) => `
You are an expert interviewer conducting a mock interview for a ${role} position.
The difficulty level is ${difficulty}.

**CORE INSTRUCTION**:
You must function as an autonomous agent with an explicit "Observe-Reason-Act" loop.
For every turn, you must output a JSON object containing your internal thought process and your external response.

**JSON FORMAT**:
{
  "observation": "Analyze what the user just said (or if they stayed silent).",
  "analysis": "Evaluate the quality of the answer. Is it correct? Vague? Off-topic?",
  "strategy": "Decide your next move. Should you probe deeper? Move to the next topic? Give a hint?",
  "response": "The actual spoken response to the candidate. Keep this concise (under 3-4 sentences)."
}

**BEHAVIOR GUIDELINES**:
1.  **Topic Management**: You MUST cover the following areas in order:
    *   **Introduction**: Brief ice-breaker.
    *   **Experience/Projects**: Ask about their past work or specific projects.
    *   **Technical Skills**: Specific questions related to the role (e.g., React, Python).
    *   **CS Fundamentals**: Data Structures, Algorithms, or System Design.
2.  **Depth Control**:
    *   Ask **maximum 1-2 follow-up questions** per topic.
    *   If the candidate answers correctly and confidently, **move to the next topic** immediately.
    *   Do NOT tunnel vision on one specific concept (like HashMaps) for the entire interview.
3.  **Adaptability**:
    *   **Confused User**: Provide a hint, then move on if they still struggle.
    *   **Efficient User**: Ask one deep follow-up, then switch topics.
    *   **Chatty User**: Acknowledge and steer back to the *next* topic.
4.  **Tone**: Professional, encouraging, but objective.
5.  **Feedback**: Do NOT provide a full evaluation in the "response".

Start by introducing yourself and asking the first question (e.g., "Tell me about yourself").
`;

export async function generateResponse(apiKey, messages, role, difficulty) {
    if (!apiKey) throw new Error("API Key is missing");

    // This is a placeholder for the actual API call.
    // We will likely use the fetch API to call the provider's endpoint directly
    // to avoid needing a backend proxy for this demo.

    // For Gemini:
    const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`;

    const systemInstruction = SYSTEM_PROMPT_TEMPLATE(role, difficulty);

    // Format messages for Gemini
    // Gemini expects: { role: "user" | "model", parts: [{ text: "..." }] }
    // We need to prepend the system prompt or include it in the first message if system instruction isn't supported in the specific endpoint version used purely via REST without the SDK.
    // 1.5 Flash supports system_instruction.

    const contents = messages.map(m => ({
        role: m.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: m.content }]
    }));

    try {
        const response = await fetch(API_URL, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                system_instruction: {
                    parts: [{ text: systemInstruction }]
                },
                contents: contents,
                generationConfig: {
                    maxOutputTokens: 1000, // Increased for JSON overhead
                    temperature: 0.7,
                    responseMimeType: "application/json" // Force JSON output
                }
            })
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.error?.message || 'Failed to fetch response');
        }

        const data = await response.json();

        if (!data.candidates || data.candidates.length === 0) {
            console.error("No candidates returned:", data);
            if (data.promptFeedback) {
                throw new Error(`Safety block: ${data.promptFeedback.blockReason}`);
            }
            throw new Error("No response generated by the model.");
        }

        const candidate = data.candidates[0];
        if (!candidate.content || !candidate.content.parts || !candidate.content.parts[0]) {
            console.error("Invalid candidate structure:", candidate);
            throw new Error("Model returned an incomplete response.");
        }

        const rawText = candidate.content.parts[0].text;

        try {
            // Parse the JSON output
            const agentOutput = JSON.parse(rawText);

            // Return the full object so the UI can use the reasoning fields
            return agentOutput;
        } catch (e) {
            console.error("Failed to parse Agent JSON:", rawText);
            // Fallback if model fails to output JSON (rare with responseMimeType)
            return {
                observation: "Error parsing agent thought.",
                analysis: "Model output was not valid JSON.",
                strategy: "Fallback to raw text.",
                response: rawText
            };
        }

    } catch (error) {
        console.error("LLM Error:", error);
        throw error;
    }
}

export async function generateFeedback(apiKey, messages, role) {
    // Similar to above, but asks for a JSON report card.
    const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`;

    // Filter out the internal reasoning from messages before sending to feedback generation
    // The messages array might now contain objects or strings depending on how we store them.
    // We need to ensure we only send the "content" (spoken text) to the feedback model
    // to avoid confusing it with the JSON structure.

    const cleanMessages = messages.map(m => {
        try {
            // If the content is a JSON string (from previous turns), parse it and extract 'response'
            // However, in the context, we should probably store only the spoken text in 'messages' 
            // OR handle the extraction here. 
            // Let's assume 'messages' in context will store the simple text for simplicity in this function,
            // OR we handle it if it's the full object.
            // Actually, to keep history clean for the *next* turn of generateResponse, 
            // we should probably store the *spoken* text in the main message history, 
            // and store the *reasoning* separately or in a metadata field.
            // For now, let's assume the 'content' passed here is the spoken text.
            return m;
        } catch (e) {
            return m;
        }
    });

    const prompt = `
  The interview is over. Here is the transcript:
  ${JSON.stringify(cleanMessages)}
  
  Please evaluate the candidate for the ${role} role.
  Return a JSON object with the following structure:
  {
    "score": number (0-100),
    "strengths": ["string", "string"],
    "weaknesses": ["string", "string"],
    "summary": "string"
  }
  Do not include markdown formatting like \`\`\`json. Just the raw JSON.
  `;

    try {
        const response = await fetch(API_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ role: 'user', parts: [{ text: prompt }] }]
            })
        });

        const data = await response.json();

        if (!data.candidates || data.candidates.length === 0) {
            throw new Error("No feedback generated.");
        }

        const candidate = data.candidates[0];
        if (!candidate.content || !candidate.content.parts || !candidate.content.parts[0]) {
            throw new Error("Invalid feedback structure.");
        }

        const text = candidate.content.parts[0].text;
        // Clean up potential markdown code blocks if the model ignores the instruction
        const cleanText = text.replace(/```json/g, '').replace(/```/g, '').trim();
        return JSON.parse(cleanText);
    } catch (error) {
        console.error("Feedback Error:", error);
        return { score: 0, strengths: [], weaknesses: ["Error generating feedback"], summary: "Could not generate report." };
    }
}
